{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression polynomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"Income\", y=\"MntWines\", color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df[\"Income\"] ** 2, y=df[\"MntWines\"], color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    x=df[\"Income\"],\n",
    "    y=df[\"MntWines\"],\n",
    "    scatter_kws={\"color\": \"black\"},\n",
    "    line_kws={\"color\": \"red\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    x=df[\"Income\"] ** 2,\n",
    "    y=df[\"MntWines\"],\n",
    "    scatter_kws={\"color\": \"black\"},\n",
    "    line_kws={\"color\": \"red\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    x=df[\"Income\"] ** 3,\n",
    "    y=df[\"MntWines\"],\n",
    "    scatter_kws={\"color\": \"black\"},\n",
    "    line_kws={\"color\": \"red\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régression linéaire basique\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[[\"Income\"]] ** 2)\n",
    "y = np.array(df[[\"MntWines\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer les données et la courbe de régression polynomiale\n",
    "plt.scatter(df[\"Income\"], y, label=\"Données\", color=\"black\")\n",
    "plt.scatter(df[\"Income\"], reg.predict(X), label=\"Régression polynomiale\", color=\"red\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Régression polynomiale d'un cube de données synthétiques\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la régression polynomiale\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les données en matrice de caractéristiques polynomiales\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on donne une variable $V$, PolynomialFeatures crée les variables\n",
    "- $1$\n",
    "- $V$\n",
    "- $V^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on donne les variables $V$ et $W$, PolynomialFeatures crée les variables\n",
    "- $1$\n",
    "- $V$\n",
    "- $W$\n",
    "- $V \\times W$\n",
    "- $V^2$\n",
    "- $W^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(attention à l'explosion combinatoire du nombre de variables !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle de régression linéaire sur les données transformées\n",
    "reg = LinearRegression().fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer les données et la courbe de régression polynomiale\n",
    "plt.scatter(df[\"Income\"], y, label=\"Données\", color=\"black\")\n",
    "plt.scatter(\n",
    "    df[\"Income\"], reg.predict(X_poly), label=\"Régression polynomiale\", color=\"red\"\n",
    ")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Régression polynomiale d'un cube de données synthétiques\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention au sur-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les données en matrice de caractéristiques polynomiales\n",
    "poly = PolynomialFeatures(degree=10)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle de régression linéaire sur les données transformées\n",
    "reg = LinearRegression().fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer les données et la courbe de régression polynomiale\n",
    "plt.scatter(df[\"Income\"], y, label=\"Données\", color=\"black\")\n",
    "plt.scatter(\n",
    "    df[\"Income\"], reg.predict(X_poly), label=\"Régression polynomiale\", color=\"red\"\n",
    ")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Régression polynomiale d'un cube de données synthétiques\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise à l'échelle (réduction ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: expliquer pourquoi on a envie de le faire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[var_numeriques].hist(figsize=(12, 12), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo(prof): est-ce que notre choix de variables est bon ?\n",
    "var_a_scaler = [\n",
    "    \"Year_Birth\",\n",
    "    \"Income\",\n",
    "    \"Recency\",\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Income\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Income\"] / df[\"Income\"].std()).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_a_scaler:\n",
    "    df_transforme[var] = df[var] / df[var].std()\n",
    "    df_transforme[var] -= df_transforme[var].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme[var_numeriques].hist(figsize=(12, 12), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les changements sur la matrice de corrélation sont de l'ordre de $10^{-15}$, donc extrêmement négligeables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_transforme[var_numeriques].corr() - df[var_numeriques].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour normaliser les données, nous allons utiliser la transformation de Box-Cox, définie $\\forall x > 0, $ comme ci-dessous :\n",
    "$B(x, \\lambda) = \\begin{cases} \\frac{x^{\\lambda} - 1}{\\lambda} & \\text{  si } \\lambda \\neq 0 \\\\ \\log(x) & \\text{  si } \\lambda = 0 \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette transformation est à appliquer à une variable (strictement positive), en ajustant le $\\lambda$ pour maximiser la normalité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser la librairie `scipy.stats.boxcox` qui estime le meilleur paramètre $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[var_numeriques].hist(figsize=(12, 12), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo(prof): faut-il inclure la distribution uniforme Recency ?\n",
    "# todo(prof): est-ce que notre choix de variables est bon ?\n",
    "var_a_normaliser = [\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"MntWines\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_lambdas = {}  # on garde les lambdas, pour la transformation inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_a_normaliser:\n",
    "    var_strict_positif = df[var] + df[var].min() + 1\n",
    "\n",
    "    var_apres_boxcox, l = boxcox(var_strict_positif)\n",
    "\n",
    "    df_transforme[var] = var_apres_boxcox\n",
    "    boxcox_lambdas[var] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuto : comment récupérer la fonction initiale\n",
    "# (il faut avoir récupéré le paramètre \"l\" lambda)\n",
    "\n",
    "# from scipy.special import inv_boxcox\n",
    "# initial = inv_boxcox(incbox, l)\n",
    "# initial = pd.DataFrame(initial)\n",
    "# sns.histplot(initial, bins=50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_transforme[\"MntWines\"], bins=50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme[var_numeriques].hist(figsize=(12, 12), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: analyser les résultats, notamment l'impact sur la matrice de corrélation (du coup, mettre ci-dessous la matrice de corrélation pré-transformation et comparer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    df_transforme[var_numeriques].corr() - df[var_numeriques].corr(),\n",
    "    cmap=\"BrBG\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme[var_numeriques].corr() - df[var_numeriques].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Matrice de corrélation des variables numériques avant transformation\")\n",
    "sns.heatmap(\n",
    "    df[var_numeriques].corr()[df[var_numeriques].corr().abs() > 0.5],\n",
    "    annot=True,\n",
    "    cmap=\"BrBG\",\n",
    "    linewidths=0.5,\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Matrice de corrélation des variables numériques après transformation\")\n",
    "sns.heatmap(\n",
    "    df_transforme[var_numeriques].corr()[\n",
    "        df_transforme[var_numeriques].corr().abs() > 0.5\n",
    "    ],\n",
    "    annot=True,\n",
    "    cmap=\"BrBG\",\n",
    "    linewidths=0.5,\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: One Hot Encoding, Target Encoding, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse multi-variée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df_apres_scale = pd.DataFrame(\n",
    "    scaler.fit_transform(df_transforme[var_numeriques]),\n",
    "    columns=df[var_numeriques].columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = KMeans(n_clusters=3)\n",
    "k4 = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3.fit(df_apres_scale[var_numeriques])\n",
    "k4.fit(df_apres_scale[var_numeriques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = k3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x=\"Income\", hue=\"cluster\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df, x=\"Year_Birth\", y=\"Income\", hue=\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[var_numeriques + [\"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = k4.labels_\n",
    "sns.histplot(df[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x=\"Income\", hue=\"cluster\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df, x=\"Year_Birth\", y=\"Income\", hue=\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: centrer / réduire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apres_scale = pd.DataFrame(\n",
    "    scaler.fit_transform(df[var_numeriques]), columns=df[var_numeriques].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apres_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for var in var_numeriques:\n",
    "#     _, ax = plt.subplots(1, 2, figsize=(8, 2))\n",
    "#     sns.boxplot(df_apres_scale[var], width=0.25, ax=ax[0])\n",
    "#     sns.histplot(df_apres_scale[var], kde=True, ax=ax[1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp = PCA(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp.fit(df_apres_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_expliquee = pd.Series(\n",
    "    acp.explained_variance_ratio_, index=df[var_numeriques].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_expliquee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_expliquee.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp = pd.DataFrame(acp.fit_transform(df_apres_scale), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_acp, x=0, y=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cercle de corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_pca_correlation_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, correlation_matrix = plot_pca_correlation_graph(\n",
    "    df_apres_scale,\n",
    "    df_apres_scale.columns,\n",
    "    X_pca=df_acp.iloc[:, :2],\n",
    "    explained_variance=acp.explained_variance_[:2],\n",
    "    dimensions=(1, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"BrBG\",\n",
    "    linewidths=0.5,\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp[\"clusterk3\"] = k3.labels_\n",
    "df_acp[\"clusterk4\"] = k4.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_acp, x=0, y=1, hue=\"clusterk3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_acp, x=0, y=1, hue=df[\"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_acp, x=0, y=2, hue=df[\"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_acp, x=0, y=1, hue=\"clusterk4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Factorielle des Correspondances (AFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_contingence = pd.crosstab(df[\"Kidhome\"], df[\"Teenhome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_contingence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = prince.CA(\n",
    "    # n_components=3,\n",
    "    # n_iter=3,\n",
    "    # copy=True,\n",
    "    # check_input=True,\n",
    "    # engine='sklearn',\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "ca = ca.fit(table_contingence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.plot(table_contingence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_contingence = pd.crosstab(df[\"Marital_Status\"], df[\"Education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_contingence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = prince.CA(random_state=0)\n",
    "ca = ca.fit(table_contingence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.plot(table_contingence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: à interpréter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des Correspondances Multiples (ACM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = prince.MCA(random_state=0)\n",
    "mca = mca.fit(df[var_categoriques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.plot(df[var_categoriques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: à interpréter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[var_numeriques]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Response\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=log_reg.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=log_reg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: commenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: refaire la régression PLS mais PAS sur une variable catégorique (erreur ici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de l'objet PLSRegression avec 2 composantes PLS\n",
    "pls = PLSRegression(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage du modèle sur les données\n",
    "pls.fit(df_transforme[var_numeriques], df_transforme[\"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction de la variable cible sur de nouvelles données\n",
    "y_pred = pls.predict(df_transforme[var_numeriques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation de la performance du modèle\n",
    "r2 = pls.score(df_transforme[var_numeriques], df_transforme[\"Response\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle simple : une variable à expliquer Y et une seule variable explicative X.  \n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$$\n",
    "\n",
    "Hypothèses à vérifier pour la régression linéaire simple :  \n",
    "\n",
    "1) il existe une corrélation linéaire entre X et Y\n",
    "\n",
    "1) la distribution de l’erreur ε est indépendante de la variable X (exogénéité)\n",
    "\n",
    "2) l'erreur suit une loi normale centrée i.e. E(ε) = 0\n",
    "\n",
    "3) l’erreur est de variance constante (homoscédasticité)\n",
    "i.e Var(εi) = s, s une constante\n",
    "\n",
    "4) les erreurs sont indépendantes (absence d'autocorrélation)\n",
    "i.e. Cov(εi, εj) = 0, pour tout i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_transforme[\"Income\"])\n",
    "Y = np.array(df_transforme[\"NumStorePurchases\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 1 : corrélation linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Le coefficient de corrélation linéaire entre X et Y vaut\",\n",
    "    pearsonr(X, Y)[0],\n",
    "    \"la pvalue associée vaut\",\n",
    "    pearsonr(X, Y)[1],\n",
    "    \"il existe donc bien une relation linéaire entre X et Y.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train.reshape(-1, 1), Y_train)\n",
    "Y_train_hat = model.predict(X_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, Y_train, color=\"black\")\n",
    "plt.plot(X_train, Y_train_hat, color=\"red\")\n",
    "plt.title(\"Régression linéaire du nombre d'achats en magasin en fonction du revenu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train.reshape(-1, 1), Y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation de régression :\n",
    "\n",
    "$$y_i = 0.46 + 2.21 * x_i$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 2 : exogénéité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_train - Y_train_hat\n",
    "\n",
    "plt.scatter(X_train, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Le coefficient de corrélation entre X et les residus vaut\",\n",
    "    pearsonr(X_train, residuals)[0],\n",
    "    \". On a bien indépendance et donc exogénéité.\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 3 : l'erreur suit une loi normale centrée i.e. E(ε) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals, density=True)\n",
    "\n",
    "x = np.linspace(-7, 7, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1))\n",
    "plt.title(\"Histogramme des résidus en superposition avec la densité de la loi normale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La moyenne des résidus vaut\", statistics.mean(residuals))\n",
    "print(\"Mais les résidus ne suivent pas une loi normale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line=\"45\")\n",
    "print(\"On constate sur le qqplot que les points ne suivent pas la droite x = y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Un test de shapiro, pour tester l'hypothèse de normalité, nous donne une pvalue de\",\n",
    "    stats.shapiro(residuals)[1],\n",
    "    \". On rejette l'hypothèse nulle et on conclut que les résidus ne suivent pas une loi normale.\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 4 : homoscédasticité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residuals, \"bo\")\n",
    "plt.title(\"Nuage de points des résidus\")\n",
    "abline(0, 7)\n",
    "abline(0, -7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.compat import lzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = smf.ols(\"NumStorePurchases ~ Income\", data=df_transforme).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_test = sms.het_breuschpagan(fit.resid, fit.model.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_names = [\"Lagrange multiplier statistic\", \"p-value\", \"f-value\", \"f p-value\"]\n",
    "print(lzip(bp_names, bp_test))\n",
    "print(\"Il y a bien homoscédasticité.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 5 : absence d'autocorrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(residuals)\n",
    "print(\"On remarque une absence d'autocorrélation.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance de Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = fit.get_influence()\n",
    "cooks = influence.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, cooks[0])\n",
    "plt.xlabel(\"Revenus\")\n",
    "plt.ylabel(\"Distances de Cook\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_indexes = [i for i, x in enumerate(cooks[0] > 0.005) if x]\n",
    "print(cooks_indexes)\n",
    "# affiche les indexes des individus dont les distances de cook dépassent une certaine valeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_plot(fit)\n",
    "print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité d'ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le R² du modèle vaut {model.score(X_train.reshape(-1, 1), Y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"R² du modèle sur les données d'entraînement = {model.score(X_train.reshape(-1, 1), Y_train)}\"\n",
    ")\n",
    "print(\n",
    "    f\"R² du modèle sur les données de test = {model.score(X_test.reshape(-1, 1), Y_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = model.predict(X_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, Y_test, color=\"black\")\n",
    "plt.plot(X_test, Y_test_hat, color=\"red\")\n",
    "plt.title(\"Nombre d'achats en magasin en fonction du revenu : données test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: cross-validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire multiple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les besoins de la régression linéaire, nous créons une variable Childhome étant égale à la somme de Teenhome et de Kidhome.  \n",
    "Nous créons également des variables muettes (dummy variables) pour inclure les variables catégoriques `Education` et `Marital_status` à la régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_transforme.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.get_dummies(df_reg, columns=[\"Education\", \"Marital_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette régression, on suppose que l'entreprise veut profiler au mieux les clients qui achètent dans le magasin. C'est pourquoi la variable d'intérêt pour la régression sera le `nombre d'achats en magasin`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transforme[\n",
    "    [\n",
    "        \"Income\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "        \"Year_Birth\",\n",
    "        \"NbChildren\",\n",
    "        \"Recency\",\n",
    "        \"NbAcceptedCampaigns\",\n",
    "    ]\n",
    "]\n",
    "Y = df_transforme[\"NumStorePurchases\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple_sm = sm.OLS(Y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple_sm.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité d'ajustement du modèle avant suppression de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y, Y_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y, Y_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y, Y_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réduction du nombre de variables explicatives par les critères AIC / BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic_OLS(X):  # entrer X le dataframe des variables explicatives\n",
    "    aic_list = []\n",
    "    for col in X.columns:\n",
    "        X_temp = X.drop(col, axis=1)\n",
    "        model_temp = sm.OLS(Y, X_temp).fit()\n",
    "        aic_list.append([col, model_temp.aic])\n",
    "\n",
    "    return aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_OLS(X):\n",
    "    current_aic = sm.OLS(Y, X).fit().aic  # aic avec les variables actuelles\n",
    "    aic_list = aic_OLS(X)  # liste des aic par supression des variables une a une\n",
    "\n",
    "    my_bool = 0  # pour indiquer si aucune variable n'est a enlever\n",
    "    for i in range(\n",
    "        len(aic_list)\n",
    "    ):  # si l'aic diminue pour une variable supprimee, on enleve cette variable du df X\n",
    "        if aic_list[i][1] < current_aic:\n",
    "            del X[aic_list[i][0]]  # a l'interieur des crochets c'est une string\n",
    "            my_bool = 1\n",
    "\n",
    "    if my_bool == 0:\n",
    "        print(\"Le stepwise est terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_OLS(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_OLS(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple_sm = sm.OLS(Y, X).fit()\n",
    "Y_hat = model_multiple_sm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y, Y_hat)\n",
    "plt.title(\"Valeurs prédites contre vraies valeurs\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple_sm.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité d'ajustement après suppression de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y, Y_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y, Y_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y, Y_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec sci-kit learn : entraînement et tests sur des vraies valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple_sk = LinearRegression().fit(X_train, Y_train)\n",
    "Y_test_hat = model_multiple_sk.predict(X_test)\n",
    "Y_train_hat = model_multiple_sk.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, Y_test_hat)\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (valeurs test)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité d'ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des coefficients du modèle de régression linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(\n",
    "    model_multiple_sk.coef_, X.columns, columns=[\"Coefficients\"]\n",
    ")\n",
    "print(coefficients)\n",
    "print(\"Intercept\", model_multiple_sk.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transforme[\n",
    "    [\n",
    "        \"Income\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "        \"Year_Birth\",\n",
    "        \"NbChildren\",\n",
    "        \"Recency\",\n",
    "        \"NbAcceptedCampaigns\",\n",
    "    ]\n",
    "]\n",
    "Y = df_transforme[\"NumStorePurchases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.probplot(Y, dist=\"poisson\", sparams=(5), plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réduction du nombre de variables grâce au critère AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic_GLM(X, Y):  # entrer X le dataframe des variables explicatives\n",
    "    aic_list = []\n",
    "    for col in X.columns:\n",
    "        X_temp = X.drop(col, axis=1)\n",
    "        model_temp = sm.GLM(Y, X_temp, family=sm.families.Poisson()).fit()\n",
    "        aic_list.append([col, model_temp.aic])\n",
    "\n",
    "    return aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_GLM(X, Y):\n",
    "    current_aic = (\n",
    "        sm.GLM(Y, X, family=sm.families.Poisson()).fit().aic\n",
    "    )  # aic avec les variables actuelles\n",
    "    aic_list = aic_GLM(X, Y)  # liste des aic par supression des variables une a une\n",
    "\n",
    "    my_bool = 0  # pour indiquer si aucune variable n'est a enlever\n",
    "    for i in range(\n",
    "        len(aic_list)\n",
    "    ):  # si l'aic diminue pour une variable supprimee, on enleve cette variable du df X\n",
    "        if aic_list[i][1] < current_aic:\n",
    "            del X[aic_list[i][0]]  # a l'interieur des crochets c'est une string\n",
    "            my_bool = 1\n",
    "\n",
    "    if my_bool == 0:\n",
    "        print(\"Le stepwise est terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_GLM(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_GLM(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model = sm.GLM(Y_train, X_train, family=sm.families.Poisson()).fit()\n",
    "Y_test_hat = poisson_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y, Y_hat)\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (valeurs test)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y, Y_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y, Y_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y, Y_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression polynomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transforme[\n",
    "    [\n",
    "        \"Income\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "        \"Year_Birth\",\n",
    "        \"Childhome\",\n",
    "        \"Recency\",\n",
    "        \"NbAcceptedCampaigns\",\n",
    "    ]\n",
    "]\n",
    "Y = df_transforme[\"NumStorePurchases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les données en matrice de caractéristiques polynomiales\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_poly, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle de régression linéaire sur les données transformées\n",
    "polynomial_model = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = polynomial_model.predict(X_test)\n",
    "Y_train_hat = polynomial_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test_hat, Y_test)\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (valeurs test)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le modèle polynomial s'ajuste mieux aux données d'entraînement, mais est moins bon pour prédire les valeurs de test. Plus le degré des polynômes augmente, plus cet écart s'empire."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'alors, le meilleur résultat a été obtenu par la régression linéaire multiple, avec élimination des variables par critères AIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=lda.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=lda.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lda.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingClassifier(\n",
    "    estimators=[\n",
    "        # ('lr', LogisticRegression(random_state=0)),\n",
    "        (\"dt\", DecisionTreeClassifier(random_state=0)),\n",
    "        # ('rf', RandomForestClassifier(random_state=0)),\n",
    "        # ('lda', LinearDiscriminantAnalysis()),\n",
    "        (\"xgb\", xgboost.XGBClassifier(random_state=0)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=model.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
