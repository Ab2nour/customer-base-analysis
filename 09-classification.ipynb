{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des outils / jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from keras import layers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/data-cleaned-feature-engineering.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=\"ID\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme = pd.read_csv(\n",
    "    \"data/data-transformed.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=\"ID\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numeriques = [\n",
    "    \"Year_Birth\",\n",
    "    \"Income\",\n",
    "    \"Recency\",\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "    \"NumDealsPurchases\",\n",
    "    \"NumWebPurchases\",\n",
    "    \"NumCatalogPurchases\",\n",
    "    \"NumStorePurchases\",\n",
    "    \"NumWebVisitsMonth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoriques = [\n",
    "    \"Education\",\n",
    "    \"Marital_Status\",\n",
    "    \"Kidhome\",\n",
    "    \"Teenhome\",\n",
    "    \"AcceptedCmp1\",\n",
    "    \"AcceptedCmp2\",\n",
    "    \"AcceptedCmp3\",\n",
    "    \"AcceptedCmp4\",\n",
    "    \"AcceptedCmp5\",\n",
    "    \"Response\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions et variables utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_score(model, nom_modele, y_test, y_pred):\n",
    "    \"\"\"Ajoute le score F1 de la classe 1 à score_modeles.\"\"\"\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T\n",
    "\n",
    "    score_f1_classe1 = clf_report.iloc[1, 2]\n",
    "\n",
    "    score_modeles.extend(([nom_modele, \"score_f1_classe1\", score_f1_classe1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, prefix, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Evalue tous les modèles dans `models` et sauvegarde les résultats avec un préfixe `prefix`\n",
    "    (utile pour distinguer les différentes stratégies de pré-traitement des données).\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model, model_name in models:\n",
    "        name = f\"{prefix}/{model_name}\"\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        clf_report = pd.DataFrame(\n",
    "            classification_report(y_test, y_pred, output_dict=True)\n",
    "        ).T\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=LABELS, normalize=\"true\")\n",
    "        # sns.heatmap(cm, annot=True, cmap=\"Purples\", vmin=0, vmax=1)\n",
    "\n",
    "        score_f1_classe1 = clf_report.iloc[1, 2]\n",
    "\n",
    "        results.append([name, score_f1_classe1])\n",
    "        ajout_score(model, name, y_test, y_pred)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liste des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    [DummyClassifier(strategy=\"uniform\", random_state=0), \"DummyClassifier_Uniform\"],\n",
    "    [\n",
    "        DummyClassifier(strategy=\"constant\", constant=1, random_state=0),\n",
    "        \"DummyClassifier_Constant1\",\n",
    "    ],\n",
    "    [LogisticRegression(random_state=0), \"LogisticRegression\"],\n",
    "    [LinearDiscriminantAnalysis(), \"LinearDiscriminantAnalysis\"],\n",
    "    [DecisionTreeClassifier(random_state=0), \"DecisionTreeClassifier\"],\n",
    "    [RandomForestClassifier(random_state=0), \"RandomForestClassifier\"],\n",
    "    [xgboost.XGBClassifier(random_state=0), \"XGBClassifier\"],\n",
    "    [LinearSVC(random_state=0), \"LinearSVC\"],\n",
    "    [BernoulliNB(), \"BernoulliNB\"],\n",
    "    [ComplementNB(), \"ComplementNB\"],\n",
    "    [KNeighborsClassifier(), \"KNeighborsClassifier\"],\n",
    "    [\n",
    "        VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", LogisticRegression(random_state=0)),\n",
    "                (\"dt\", RandomForestClassifier(random_state=0)),\n",
    "                (\"lda\", LinearDiscriminantAnalysis()),\n",
    "                (\"xgb\", xgboost.XGBClassifier(random_state=0)),\n",
    "            ],\n",
    "            voting=\"soft\",\n",
    "        ),\n",
    "        \"VotingClassifier\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df_transforme.drop(columns=[\"Response\", \"Dt_Customer\"]))\n",
    "y = df[[\"Response\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"défaut\"\n",
    "results = evaluate_models(models, prefix, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Équilibrage des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling (manuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples0 = df_transforme[df_transforme[\"Response\"] == 0].sample(350, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eq = pd.concat((samples0, df_transforme[df_transforme[\"Response\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eq[\"Response\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eq = X_eq.pop(\"Response\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eq = pd.get_dummies(X_eq.drop(columns=[\"Dt_Customer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_eq, y_eq, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"éq_classes\"\n",
    "results = evaluate_models(models, prefix, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(\n",
    "    categorical_features=[  # todo: générer cette liste automatiquement...\n",
    "        2,\n",
    "        3,\n",
    "        5,\n",
    "        6,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        24,\n",
    "        25,\n",
    "        26,\n",
    "        27,\n",
    "    ],\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"SMOTE\"\n",
    "results = evaluate_models(models, prefix, X_train_sm, X_test, y_train_sm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(\"float32\")\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "X_test = np.asarray(X_test).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(400, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(400, activation=\"relu\"),\n",
    "        layers.Dense(400, activation=\"sigmoid\"),\n",
    "        layers.Dense(400, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"binary_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    # validation_split=0.2,\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0,  # hide the output because we have so many epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, [\"loss\", \"val_loss\"]].plot()\n",
    "history_df.loc[5:, [\"binary_accuracy\", \"val_binary_accuracy\"]].plot()\n",
    "\n",
    "print(\n",
    "    (\"Best Validation Loss: {:0.4f}\" + \"\\nBest Validation Accuracy: {:0.4f}\").format(\n",
    "        history_df[\"val_loss\"].min(), history_df[\"val_binary_accuracy\"].max()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_pred > 0.5, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_old = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=LABELS)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LABELS)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_modele = \"Réseau de Neurones\"\n",
    "ajout_score(model, nom_modele, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles_df = pd.DataFrame(score_modeles, columns=[\"Modèle\", \"Métrique\", \"Valeur\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles_df.to_csv(\"data/results/classifications.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
