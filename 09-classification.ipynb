{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des outils / jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from keras import layers\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/data-cleaned-feature-engineering.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=\"ID\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numeriques = [\n",
    "    \"Year_Birth\",\n",
    "    \"Income\",\n",
    "    \"Recency\",\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "    \"NumDealsPurchases\",\n",
    "    \"NumWebPurchases\",\n",
    "    \"NumCatalogPurchases\",\n",
    "    \"NumStorePurchases\",\n",
    "    \"NumWebVisitsMonth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoriques = [\n",
    "    \"Education\",\n",
    "    \"Marital_Status\",\n",
    "    \"Kidhome\",\n",
    "    \"Teenhome\",\n",
    "    \"AcceptedCmp1\",\n",
    "    \"AcceptedCmp2\",\n",
    "    \"AcceptedCmp3\",\n",
    "    \"AcceptedCmp4\",\n",
    "    \"AcceptedCmp5\",\n",
    "    \"Response\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions et variables utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tableau.** Informations sur notre classification\n",
    "\n",
    "|:---------------------------|:----------------------------------|\n",
    "| **Objectif métier**        | Prédire l'acceptation à une campagne marketing |\n",
    "| **Problème technique**     | Classification binaire supervisée |\n",
    "| **Métrique**               | Score F1 sur la classe 1 (clients qui acceptent)<br>À score F1 égal, on choisit la meilleure précision sur la classe 1 |\n",
    "| **Méthode d'entraînement** | Validation croisée en 5 blocs     |\n",
    "| **Pré-traitement**         | Variables quantitatives : centrer/réduire<br>Variables qualitatives : OneHot Encoding (Tableau Disjonctif Complet) |\n",
    "| **Équilibrage des classes**| 1) Aucun<br>2) Sous-échantillonnage aléatoire manuel<br>3) Sur-échantillonnage avec SMOTE |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, prefix, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Evalue tous les modèles dans `models` et sauvegarde les résultats avec un préfixe `prefix`\n",
    "    (utile pour distinguer les différentes stratégies de pré-traitement des données).\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model, model_name in models:\n",
    "        name = f\"{prefix}/{model_name}\"\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        precision = accuracy_score(y_test, y_pred)\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            scoring=make_scorer(f1_score, labels=[LABELS[1]]),\n",
    "        )\n",
    "        scores_mean = scores.mean()\n",
    "        scores_std = scores.std()\n",
    "\n",
    "        # clf_report = pd.DataFrame(\n",
    "        #     classification_report(y_test, y_pred, output_dict=True)\n",
    "        # ).T\n",
    "        # cm = confusion_matrix(y_test, y_pred, labels=LABELS, normalize=\"true\")\n",
    "        # # sns.heatmap(cm, annot=True, cmap=\"Purples\", vmin=0, vmax=1)\n",
    "        #\n",
    "        # score_f1_classe1 = clf_report.iloc[1, 2]\n",
    "\n",
    "        results.append(\n",
    "            [\n",
    "                name,\n",
    "                scores_mean,\n",
    "                #             scores_std,\n",
    "            ]\n",
    "        )\n",
    "        score_modeles.extend(\n",
    "            (\n",
    "                [\n",
    "                    name,\n",
    "                    \"score_f1_classe1\",\n",
    "                    scores_mean,\n",
    "                    #               scores_std,\n",
    "                    precision,\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liste des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tableau.** Liste des modèles de notre étude\n",
    "\n",
    "|:---------------------------|:----------------------------------|\n",
    "| **Modèles de référence**   | Classificateur Idiot Uniforme (50% de oui et 50% de non)<br>Classificateur Idiot Constant 1 (100% de oui) |\n",
    "| **Modèles linéaires**  | Régression logistique<br>Analyse Discriminante Linéaire |\n",
    "| **Arbres de décision**               | Arbre de décision<br>Forêt d'arbres de décision (Random Forest) |\n",
    "| **Gradient Boosting** | XGBoost<br>LightGBM<br>CatBoost |\n",
    "| **Machine à vecteurs de support (SVM)** | Classificateur SVM linéaire |\n",
    "| **k plus proches voisins (k-NN)** | Classificateur k-nn (5 voisins)<br>Classificateur k-nn (15 voisins) |\n",
    "| **Modèle de vote**| Modèle de \"Vote à la majorité\" sur 5 modèles :<br>- Régression logistique<br>- Analyse discriminante linéaire<br>- Random Forest<br>- XGBoost<br>- CatBoost |\n",
    "| **Réseau de neurones**| Réseau de neurones à 5 couches et 1 600 neurones |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    [DummyClassifier(strategy=\"uniform\", random_state=SEED), \"DummyClassifier_Uniform\"],\n",
    "    [\n",
    "        DummyClassifier(strategy=\"constant\", constant=1, random_state=SEED),\n",
    "        \"DummyClassifier_Constant1\",\n",
    "    ],\n",
    "    [LogisticRegression(random_state=SEED), \"LogisticRegression\"],\n",
    "    [LinearDiscriminantAnalysis(), \"LinearDiscriminantAnalysis\"],\n",
    "    [DecisionTreeClassifier(random_state=SEED), \"DecisionTreeClassifier\"],\n",
    "    [RandomForestClassifier(random_state=SEED), \"RandomForestClassifier\"],\n",
    "    [xgboost.XGBClassifier(random_state=SEED), \"XGBClassifier\"],\n",
    "    [CatBoostClassifier(random_state=SEED, verbose=False), \"CatBoostClassifier\"],\n",
    "    [LGBMClassifier(random_state=SEED), \"LGBMClassifier\"],\n",
    "    [LinearSVC(random_state=SEED), \"LinearSVC\"],\n",
    "    # [BernoulliNB(), \"BernoulliNB\"],\n",
    "    # [ComplementNB(), \"ComplementNB\"],\n",
    "    [KNeighborsClassifier(), \"KNeighborsClassifier5\"],\n",
    "    [KNeighborsClassifier(n_neighbors=15), \"KNeighborsClassifier15\"],\n",
    "    [\n",
    "        VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", LogisticRegression(random_state=SEED)),\n",
    "                (\"lda\", LinearDiscriminantAnalysis()),\n",
    "                (\"dt\", RandomForestClassifier(random_state=SEED)),\n",
    "                (\"xgb\", xgboost.XGBClassifier(random_state=SEED)),\n",
    "                (\"catboost\", CatBoostClassifier(random_state=SEED, verbose=False)),\n",
    "            ],\n",
    "            voting=\"soft\",\n",
    "        ),\n",
    "        \"VotingClassifier\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Scaler & OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat_non_ohe = [\n",
    "    \"AcceptedCmp1\",\n",
    "    \"AcceptedCmp2\",\n",
    "    \"AcceptedCmp3\",\n",
    "    \"AcceptedCmp4\",\n",
    "    \"AcceptedCmp5\",\n",
    "    \"Response\",\n",
    "    \"HasAcceptedCampaigns\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"HasAcceptedCampaigns\"] = df[\"HasAcceptedCampaigns\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat_ohe = [\n",
    "    \"Education\",\n",
    "    \"Marital_Status\",\n",
    "    \"Kidhome\",\n",
    "    \"Teenhome\",\n",
    "    \"NbAcceptedCampaigns\",\n",
    "    \"NbChildren\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe.fit_transform(df[var_cat_ohe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[var_categoriques].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    remainder=\"passthrough\",\n",
    "    transformers=[\n",
    "        (\"ohe\", OneHotEncoder(), var_cat_ohe),\n",
    "        (\"scaler\", RobustScaler(), var_numeriques),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Response\", \"Dt_Customer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_df = pd.DataFrame(preprocessor.transform(X), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(steps=[(\"scaler\", RobustScaler())])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     remainder=\"passthrough\",\n",
    "#     transformers=[\n",
    "#         (\"std\", standard_transformer, [3]),\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_sampling_manuel = Pipeline(steps=[()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Response\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nouveau_df, y, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"défaut\"\n",
    "results = evaluate_models(models, prefix, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Équilibrage des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling (manuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples0 = df[df[\"Response\"] == 0].sample(350, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_eq = pd.concat((samples0, df[df[\"Response\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_eq[\"Response\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_eq = X_eq.pop(\"Response\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_eq = pd.get_dummies(X_eq.drop(columns=[\"Dt_Customer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Response\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_A_SUPPRIMER = 1400\n",
    "drop_indices = np.random.choice(\n",
    "    nouveau_df[y[\"Response\"] == 0].index, NB_A_SUPPRIMER, replace=False\n",
    ")\n",
    "df_subset = nouveau_df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eq = y.drop(index=drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_subset, y_eq, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"éq_classes\"\n",
    "results = evaluate_models(models, prefix, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(X.select_dtypes(include=[\"category\", \"int\", \"bool\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_index = list(map(lambda c: list(X.columns).index(c), cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.iloc[:, cat_cols_index].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(\n",
    "    categorical_features=cat_cols_index,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nouveau_df, y, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"SMOTE\"\n",
    "results = evaluate_models(models, prefix, X_train_sm, X_test, y_train_sm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_subset, y_eq, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(\"float32\")\n",
    "y_train = np.asarray(y_train).astype(\"float32\")\n",
    "X_test = np.asarray(X_test).astype(\"float32\")\n",
    "y_test = np.asarray(y_test).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(400, activation=\"relu\", input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(400, activation=\"relu\"),\n",
    "        layers.Dense(400, activation=\"sigmoid\"),\n",
    "        layers.Dense(400, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"binary_accuracy\"],  # \"binary_accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    # validation_split=0.2,\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0,  # hide the output because we have so many epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, [\"loss\", \"val_loss\"]].plot()\n",
    "history_df.loc[5:, [\"binary_accuracy\", \"val_binary_accuracy\"]].plot()\n",
    "\n",
    "print(\n",
    "    (\"Best Validation Loss: {:0.4f}\" + \"\\nBest Validation Accuracy: {:0.4f}\").format(\n",
    "        history_df[\"val_loss\"].min(), history_df[\"val_binary_accuracy\"].max()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_pred > 0.5, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_old = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=LABELS)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LABELS)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_modele = \"Réseau de Neurones\"\n",
    "# ajout_score(model, nom_modele, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_colonnes = preprocessor.get_feature_names_out(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_colonnes = list(map(lambda x: x.split(\"__\")[1], nom_colonnes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = models[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(fi.reshape((1, len(fi))), columns=nom_colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = fi.sort_values(\n",
    "    by=0, axis=1, ascending=False\n",
    ")  # trier les colonnes en fonction de la ligne 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 12))\n",
    "plt.title(\"Importance donnée par le modèle RandomForest\")\n",
    "sns.barplot(fi, orient=\"h\", color=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(result.importances_std < 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_results = result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_results = pd.DataFrame(\n",
    "    pi_results.reshape((1, len(pi_results))), columns=nom_colonnes\n",
    ")\n",
    "pi_results = pi_results.sort_values(by=0, axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 12))\n",
    "plt.title(\"Importance de Permutation du modèle RandomForest\")\n",
    "sns.barplot(pi_results, orient=\"h\", color=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles_df = pd.DataFrame(\n",
    "    score_modeles, columns=[\"Modèle\", \"Métrique\", \"Valeur\", \"Précision\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_modeles_df.to_csv(\"data/results/classifications.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
