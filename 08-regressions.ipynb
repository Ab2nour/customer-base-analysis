{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des outils / jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/data-cleaned-feature-engineering.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=\"ID\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transforme = pd.read_csv(\n",
    "    \"data/data-transformed.csv\",\n",
    "    sep=\",\",\n",
    "    index_col=\"ID\",\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numeriques = [\n",
    "    \"Year_Birth\",\n",
    "    \"Income\",\n",
    "    \"Recency\",\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "    \"NumDealsPurchases\",\n",
    "    \"NumWebPurchases\",\n",
    "    \"NumCatalogPurchases\",\n",
    "    \"NumStorePurchases\",\n",
    "    \"NumWebVisitsMonth\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoriques = [\n",
    "    \"Education\",\n",
    "    \"Marital_Status\",\n",
    "    \"Kidhome\",\n",
    "    \"Teenhome\",\n",
    "    \"Complain\",\n",
    "    \"AcceptedCmp1\",\n",
    "    \"AcceptedCmp2\",\n",
    "    \"AcceptedCmp3\",\n",
    "    \"AcceptedCmp4\",\n",
    "    \"AcceptedCmp5\",\n",
    "    \"Response\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[var_numeriques]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Response\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, labels=log_reg.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=log_reg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: commenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: refaire la régression PLS mais PAS sur une variable catégorique (erreur ici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de l'objet PLSRegression avec 2 composantes PLS\n",
    "pls = PLSRegression(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage du modèle sur les données\n",
    "pls.fit(df_transforme[var_numeriques], df_transforme[\"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction de la variable cible sur de nouvelles données\n",
    "y_pred = pls.predict(df_transforme[var_numeriques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation de la performance du modèle\n",
    "r2 = pls.score(df_transforme[var_numeriques], df_transforme[\"Response\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle simple : une variable à expliquer Y et une seule variable explicative X.\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$$\n",
    "\n",
    "Hypothèses à vérifier pour la régression linéaire simple :\n",
    "\n",
    "1) il existe une corrélation linéaire entre X et Y\n",
    "\n",
    "1) la distribution de l’erreur ε est indépendante de la variable X (exogénéité)\n",
    "\n",
    "2) l'erreur suit une loi normale centrée i.e. E(ε_i) = 0\n",
    "\n",
    "3) l’erreur est de variance constante (homoscédasticité)\n",
    "i.e Var(ε_i) = s, une constante\n",
    "\n",
    "4) les erreurs sont indépendantes (absence d'autocorrélation)\n",
    "i.e. Cov(εi, εj) = 0, pour tout i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_transforme[\"Income\"])\n",
    "Y = np.array(df_transforme[\"NumStorePurchases\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 1 : corrélation linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Le coefficient de corrélation linéaire entre X et Y vaut\",\n",
    "    pearsonr(X, Y)[0],\n",
    "    \"la pvalue associée vaut\",\n",
    "    pearsonr(X, Y)[1],\n",
    "    \"il existe donc bien une relation linéaire entre X et Y.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reste des hypothèses à tester requiert d'effectuer la régression linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train.reshape(-1, 1), Y_train)\n",
    "Y_train_hat = model.predict(X_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, Y_train, color=\"black\")\n",
    "plt.plot(X_train, Y_train_hat, color=\"red\")\n",
    "plt.title(\"Régression linéaire du nombre d'achats en magasin en fonction du revenu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_, model.coef_, model.score(X_train.reshape(-1, 1), Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation de régression :\n",
    "\n",
    "$$y_i = 0.46 + 2.21 * x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 2 : exogénéité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_train - Y_train_hat\n",
    "\n",
    "plt.scatter(X_train, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Le coefficient de corrélation entre X et les residus vaut\",\n",
    "    pearsonr(X_train, residuals)[0],\n",
    "    \". On a bien indépendance et donc exogénéité.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 3 : l'erreur suit une loi normale centrée i.e. E(ε_i) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals, density=True)\n",
    "\n",
    "x = np.linspace(-7, 7, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1))\n",
    "plt.title(\"Histogramme des résidus en superposition avec la densité de la loi normale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La moyenne des résidus vaut\", statistics.mean(residuals))\n",
    "print(\"Mais les résidus ne suivent pas une loi normale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line=\"45\")\n",
    "print(\"On constate sur le qqplot que les points ne suivent pas la droite x = y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Un test de shapiro, pour tester l'hypothèse de normalité, nous donne une pvalue de\",\n",
    "    stats.shapiro(residuals)[1],\n",
    "    \". On rejette l'hypothèse nulle et on conclut que les résidus ne suivent pas une loi normale.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 4 : homoscédasticité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, \"-\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residuals, \"bo\")\n",
    "plt.title(\"Nuage de points des résidus\")\n",
    "abline(0, 7)\n",
    "abline(0, -7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.OLS(Y_train, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_names = [\"F statistic\", \"p-value\"]\n",
    "gq_test = sms.het_goldfeldquandt(fit.resid, fit.model.exog)\n",
    "lzip(res_names, gq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_test = sms.het_breuschpagan(fit.resid, fit.model.exog)\n",
    "lzip(res_names, bp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le test de Goldfeld-Quandt ne nous donne pas d'hétéroscédasticité, contraiement au test de Breusch-Pagan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 5 : absence d'autocorrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(residuals)\n",
    "print(\"On remarque une absence d'autocorrélation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance de Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = fit.get_influence()\n",
    "cooks = influence.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, cooks[0])\n",
    "plt.xlabel(\"Revenus\")\n",
    "plt.ylabel(\"Distances de Cook\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_indexes = [i for i, x in enumerate(cooks[0] > 0.005) if x]\n",
    "print(cooks_indexes)\n",
    "# affiche les indexes des individus dont les distances de cook dépassent une certaine valeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_plot(fit)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité d'ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le R² du modèle vaut {model.score(X_train.reshape(-1, 1), Y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"R² du modèle sur les données d'entraînement = {model.score(X_train.reshape(-1, 1), Y_train)}\"\n",
    ")\n",
    "print(\n",
    "    f\"R² du modèle sur les données de test = {model.score(X_test.reshape(-1, 1), Y_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = model.predict(X_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, Y_test, color=\"black\")\n",
    "plt.plot(X_test, Y_test_hat, color=\"red\")\n",
    "plt.title(\"Nombre d'achats en magasin en fonction du revenu : données test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle multiple : une variable à expliquer Y et N variables explicatives X_i\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 X_i(1) + \\beta_2 X_i(2) + \\beta_3 X_i(3) + ... + \\beta_P X_i(P) + \\epsilon_i$$\n",
    "\n",
    "Hypothèses à vérifier pour la régression linéaire multiple :\n",
    "\n",
    "1) il existe une corrélation linéaire entre X_i et Y\n",
    "\n",
    "2) Cov(X_p_i, ε_j) = 0, pour tout i, j (exogénéité) et pour chaque variable explicative X_p\n",
    "\n",
    "3) l'erreur suit une loi normale centrée i.e. E(ε_i) = 0\n",
    "\n",
    "4) l’erreur est de variance constante (homoscédasticité)\n",
    "i.e Var(εi) = s, une constante\n",
    "\n",
    "5) les erreurs sont indépendantes (absence d'autocorrélation)\n",
    "i.e. Cov(εi, εj) = 0, pour tout i, j\n",
    "\n",
    "6) absence de colinéarité entre les variables explicatives,\n",
    "i.e. X_t * X est régulière, det(X_t * X) ≠ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les besoins de la régression linéaire, nous créons des variables muettes (dummy variables) pour inclure les variables catégoriques `Education` et `Marital_status` à la régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_transforme.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.get_dummies(df_reg, columns=[\"Education\", \"Marital_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette régression, on suppose que l'entreprise veut profiler au mieux les clients qui achètent dans le magasin. C'est pourquoi la variable d'intérêt pour la régression sera le `nombre d'achats en magasin`.\n",
    "\n",
    "Nos variables explicatives sont des variables numériques et des variables catégoriques transformées en variables muettes.\n",
    "Nous commençons par un grand nombre de variables explicatives puis nous en éliminerons progressivement pendant la vérifications des hypothèses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numeriques_reg = [\n",
    "    \"Income\",\n",
    "    \"Year_Birth\",\n",
    "    \"Recency\",\n",
    "    \"NbAcceptedCampaigns\",\n",
    "    \"NumWebPurchases\",\n",
    "    \"NumDealsPurchases\",\n",
    "    \"NumWebVisitsMonth\",\n",
    "    \"NumCatalogPurchases\",\n",
    "    \"MntWines\",\n",
    "    \"MntFruits\",\n",
    "    \"MntMeatProducts\",\n",
    "    \"MntFishProducts\",\n",
    "    \"MntSweetProducts\",\n",
    "    \"MntGoldProds\",\n",
    "]\n",
    "\n",
    "var_categoriques_reg = [\n",
    "    \"NbChildren\",\n",
    "    \"Education_2n Cycle\",\n",
    "    \"Education_Basic\",\n",
    "    \"Education_Graduation\",\n",
    "    \"Education_Master\",\n",
    "    \"Education_PhD\",\n",
    "    \"Marital_Status_Divorced\",\n",
    "    \"Marital_Status_Married\",\n",
    "    \"Marital_Status_Single\",\n",
    "    \"Marital_Status_Together\",\n",
    "    \"Marital_Status_Widow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg[var_categoriques_reg + var_numeriques_reg]\n",
    "Y = df_reg[\"NumStorePurchases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Nous avons\",\n",
    "    X.shape[1],\n",
    "    \"variables explicatives au début de la régression dont\",\n",
    "    X[var_numeriques_reg].shape[1],\n",
    "    \"variables numériques.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 1 : lien linéaire entre Y et les variables explicatives numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_transforme, x_vars=var_numeriques_reg[0:4], y_vars=\"NumStorePurchases\")\n",
    "sns.pairplot(df_transforme, x_vars=var_numeriques_reg[4:8], y_vars=\"NumStorePurchases\")\n",
    "sns.pairplot(df_transforme, x_vars=var_numeriques_reg[8:12], y_vars=\"NumStorePurchases\")\n",
    "sns.pairplot(df_transforme, x_vars=var_numeriques_reg[12:], y_vars=\"NumStorePurchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X[var_numeriques_reg].columns:\n",
    "    corr = pearsonr(X[x], Y)\n",
    "    print(\n",
    "        \"Le coefficient de corrélation linéaire entre Y et\",\n",
    "        x,\n",
    "        \"vaut\",\n",
    "        corr[0],\n",
    "        \"la pvalue vaut\",\n",
    "        corr[1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: faire un joli affichage avec SNS heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide déjà d'écarter la variable `Recency` de la régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X[\"Recency\"]\n",
    "var_numeriques_reg.remove(\"Recency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réalisation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiple = LinearRegression().fit(X_train, Y_train)\n",
    "Y_train_hat = model_multiple.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_train, Y_train_hat, color=\"black\")\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (donnéees d'entraînement)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 2 : exogénéité sur les variables numériques\n",
    "(Cela n'a pas de sens de tester l'exogénéité sur les variables catégoriques car la notion de corrélation ne fonctionne pas avec celles-ci.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_train - Y_train_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X_train[var_numeriques_reg].columns:\n",
    "    corr = pearsonr(X_train[x], residuals)\n",
    "    print(\n",
    "        \"Le coefficient de corrélation entre\",\n",
    "        x,\n",
    "        \"et les residus vaut\",\n",
    "        corr[0],\n",
    "        \"et la pvalue associée vaut\",\n",
    "        corr[1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a pas d'endogénéité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 3 : l'erreur suit une loi normale centrée i.e. E(ε_i) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals, density=True)\n",
    "\n",
    "x = np.linspace(-6, 6, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1))\n",
    "plt.title(\"Histogramme des résidus en superposition avec la densité de la loi normale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La moyenne des résidus vaut\", statistics.mean(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line=\"45\")\n",
    "print(\"On constate sur le qqplot que les points ne suivent pas la droite x = y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Un test de shapiro, pour tester l'hypothèse de normalité, nous donne une pvalue de\",\n",
    "    stats.shapiro(residuals)[1],\n",
    "    \". On rejette l'hypothèse nulle et on conclut que les résidus ne suivent pas une loi normale.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 4 : homoscédasticité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(residuals, \"bo\")\n",
    "plt.title(\"Nuage de points des résidus\")\n",
    "abline(0, 6.5)\n",
    "abline(0, -6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.OLS(Y_train, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_names = [\"F statistic\", \"p-value\"]\n",
    "gq_test = sms.het_goldfeldquandt(fit.resid, fit.model.exog)\n",
    "lzip(res_names, gq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_test = sms.het_breuschpagan(fit.resid, fit.model.exog)\n",
    "lzip(res_names, bp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_test = sms.het_white(fit.resid, fit.model.exog)\n",
    "lzip(res_names, white_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le test de Goldfeld-Quandt, qui vérifie la constance de la variance entre deux échantillons, ne nous donne pas d'hétéroscédasticité, contrairement aux tests de White et de Breusch-Pagan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothèse 5 : absence d'autocorrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_acf(residuals)\n",
    "print(\"On remarque une absence d'autocorrélation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction du nombre de variables explicatives par le critère AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic(X, Y, regressor=\"\"):  # entrer X le dataframe des variables explicatives,\n",
    "    # Y la variable expliquée, et le regresseur utilisé\n",
    "    aic_list = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        X_temp = X.drop(col, axis=1)\n",
    "\n",
    "        if regressor == \"linearOLS\":\n",
    "            model_temp = sm.OLS(Y, X_temp).fit()\n",
    "        elif regressor == \"GLMpoisson\":\n",
    "            model_temp = sm.GLM(Y, X_temp, family=sm.families.Poisson()).fit()\n",
    "        else:\n",
    "            return \"Entrer un régresseur valide\"\n",
    "\n",
    "        aic_list.append([col, model_temp.aic])\n",
    "\n",
    "    return aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise(X, Y, regressor=\"\"):  # entrer X le dataframe des variables explicatives,\n",
    "    # Y la variable expliquée, et le regresseur utilisé\n",
    "\n",
    "    if regressor == \"linearOLS\":\n",
    "        current_aic = sm.OLS(Y, X).fit().aic  # aic avec les variables actuelles\n",
    "    elif regressor == \"GLMpoisson\":\n",
    "        current_aic = sm.GLM(Y, X, family=sm.families.Poisson()).aic\n",
    "    else:\n",
    "        return \"Entrer un régresseur valide\"\n",
    "\n",
    "    aic_list = aic(\n",
    "        X, Y, regressor\n",
    "    )  # liste des aic par supression des variables une a une\n",
    "\n",
    "    my_bool = 0  # pour indiquer si aucune variable n'est a enlever\n",
    "    for i in range(\n",
    "        len(aic_list)\n",
    "    ):  # si l'aic diminue pour une variable supprimee, on enleve cette variable du df X\n",
    "\n",
    "        if aic_list[i][1] < current_aic:\n",
    "            del X[aic_list[i][0]]  # a l'interieur des crochets c'est une string\n",
    "            my_bool = 1\n",
    "\n",
    "    if my_bool == 0:\n",
    "        return \"L'algorithme stepwise est terminé.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if (\n",
    "        stepwise(X_train, Y_train, regressor=\"linearOLS\")\n",
    "        == \"L'algorithme stepwise est terminé.\"\n",
    "    ):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise(X_train, Y_train, regressor=\"linearOLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on refait les modèles après sélection de variables\n",
    "\n",
    "X_test = X_test[\n",
    "    X_train.columns\n",
    "]  # homogénéisation des données de test et d'entraînement\n",
    "\n",
    "fit = sm.OLS(Y_train, sm.add_constant(X_train)).fit()\n",
    "\n",
    "model_multiple = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance de Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = fit.get_influence()\n",
    "cooks = influence.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train.index, cooks[0])\n",
    "plt.xlabel(\"Index des individus\")\n",
    "plt.ylabel(\"Distances de Cook\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_indexes = [i for i, x in enumerate(cooks[0] > 0.010) if x]\n",
    "# détermine l'index dans la liste des individus dont la distance de cook dépasse 0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cooks_indexes:\n",
    "    print(X_train.iloc[[i]].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: supprimer les individus aux distances trop grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_plot(fit)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les distances de Cook ont été largement réduites par la sélection de variables au critère AIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité d'ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le R² du modèle vaut {model_multiple.score(X_train, Y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = model_multiple.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"R² du modèle sur les données d'entraînement = {model_multiple.score(X_train, Y_train)}\"\n",
    ")\n",
    "print(f\"R² du modèle sur les données de test = {model_multiple.score(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = model_multiple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, Y_test_hat, color=\"black\")\n",
    "abline(1, 0)\n",
    "plt.title(\"Valeurs prédites contre les vraies valeurs : données de test du modèle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transforme[\n",
    "    [\n",
    "        \"Income\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "        \"Year_Birth\",\n",
    "        \"NbChildren\",\n",
    "        \"Recency\",\n",
    "        \"NbAcceptedCampaigns\",\n",
    "    ]\n",
    "]\n",
    "Y = df_transforme[\"NumStorePurchases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.probplot(Y, dist=\"poisson\", sparams=(5), plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réduction du nombre de variables grâce au critère AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic_GLM(X, Y):  # entrer X le dataframe des variables explicatives\n",
    "    aic_list = []\n",
    "    for col in X.columns:\n",
    "        X_temp = X.drop(col, axis=1)\n",
    "        model_temp = sm.GLM(Y, X_temp, family=sm.families.Poisson()).fit()\n",
    "        aic_list.append([col, model_temp.aic])\n",
    "\n",
    "    return aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_GLM(X, Y):\n",
    "    current_aic = (\n",
    "        sm.GLM(Y, X, family=sm.families.Poisson()).fit().aic\n",
    "    )  # aic avec les variables actuelles\n",
    "    aic_list = aic_GLM(X, Y)  # liste des aic par supression des variables une a une\n",
    "\n",
    "    my_bool = 0  # pour indiquer si aucune variable n'est a enlever\n",
    "    for i in range(\n",
    "        len(aic_list)\n",
    "    ):  # si l'aic diminue pour une variable supprimee, on enleve cette variable du df X\n",
    "        if aic_list[i][1] < current_aic:\n",
    "            del X[aic_list[i][0]]  # a l'interieur des crochets c'est une string\n",
    "            my_bool = 1\n",
    "\n",
    "    if my_bool == 0:\n",
    "        print(\"Le stepwise est terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_GLM(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_GLM(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_model = sm.GLM(Y_train, X_train, family=sm.families.Poisson()).fit()\n",
    "Y_test_hat = poisson_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y, Y_hat)\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (valeurs test)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y, Y_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y, Y_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y, Y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression polynomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transforme[\n",
    "    [\n",
    "        \"Income\",\n",
    "        \"NumWebPurchases\",\n",
    "        \"NumDealsPurchases\",\n",
    "        \"NumWebVisitsMonth\",\n",
    "        \"NumCatalogPurchases\",\n",
    "        \"MntWines\",\n",
    "        \"MntFruits\",\n",
    "        \"MntMeatProducts\",\n",
    "        \"MntFishProducts\",\n",
    "        \"MntSweetProducts\",\n",
    "        \"MntGoldProds\",\n",
    "        \"Year_Birth\",\n",
    "        \"Childhome\",\n",
    "        \"Recency\",\n",
    "        \"NbAcceptedCampaigns\",\n",
    "    ]\n",
    "]\n",
    "Y = df_transforme[\"NumStorePurchases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer les données en matrice de caractéristiques polynomiales\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_poly, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner un modèle de régression linéaire sur les données transformées\n",
    "polynomial_model = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat = polynomial_model.predict(X_test)\n",
    "Y_train_hat = polynomial_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test_hat, Y_test)\n",
    "plt.title(\"Valeurs prédites contres vraies valeurs (valeurs test)\")\n",
    "abline(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_test, Y_test_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_test, Y_test_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_test, Y_test_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE = {mean_squared_error(Y_train, Y_train_hat)}\")\n",
    "print(f\"RMSE = {mean_squared_error(Y_train, Y_train_hat, squared=False)}\")\n",
    "print(f\"MAE = {mean_absolute_error(Y_train, Y_train_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le modèle polynomial s'ajuste mieux aux données d'entraînement, mais est moins bon pour prédire les valeurs de test. Plus le degré des polynômes augmente, plus cet écart s'empire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'alors, le meilleur résultat a été obtenu par la régression linéaire multiple, avec élimination des variables par critères AIC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
